{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSzbtWeduBsM"
      },
      "source": [
        "# Práctica 1.2. Representaciones vectoriales y clasificación de textos\n",
        "## García Rivera Bogdan Kaleb MIA-3\n",
        "\n",
        "Este proyecto  tiene como finalidad realizar una comparativa de los distintos algoritmos de machine learning con el procesamiento de lenguaje natural. Se hace uso de una base de datos de 50k de reviews de peliculas las cuales cada una de ellas tienen la etiqueta 'positive' y 'negative' respectivamente\n",
        "\n",
        "### Objetivos\n",
        "* Construir y comparar diferentes representaciones de texto: Word2Vec preentrenado (Google News), Word2Vec entrenado en un corpus propio, Bolsa de palabras (BoW), N-gramas y TF-IDF\n",
        "* Entrenar y evaluar al menos 3 modelos de clasificación de texto.\n",
        "* Comparar el desempeño (accuracy y classification report) entre representaciones vectoriales y modelos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBsDvQQLvXE-"
      },
      "source": [
        "Importando datos y algunas librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bugy1\\anaconda3\\envs\\pln\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: C:\\Users\\bugy1\\.cache\\kagglehub\\datasets\\lakshmi25npathi\\imdb-dataset-of-50k-movie-reviews\\versions\\1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "hPF2dRuAvlRy",
        "outputId": "4423382d-3777-4d63-af84-6215348aa846"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\bugy1\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\bugy1\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "df = pd.read_csv(path + '/IMDB Dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQttDvy-x-GZ"
      },
      "source": [
        "## 1. Preprocesamiento\n",
        "\n",
        "1. Preprocesamiento del texto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqxUX4sKvxGM",
        "outputId": "0e25e6f0-665e-4001-f10e-326cbf3af752"
      },
      "outputs": [],
      "source": [
        "def preprocessing(text):\n",
        "    text = text.lower()\n",
        "    # Quitar etiquetas HTML\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Quitar URLs y menciones\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "    # Quitar caracteres especiales\n",
        "    text = re.sub(r\"[^a-zA-Z\\s']\", ' ', text)\n",
        "\n",
        "    # Quitar numeros\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Quitar dobles espacios\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Tokenización\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remover stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Aplicar stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "df['tokens'] = df['review'].apply(preprocessing)\n",
        "df['clean_text'] = df['tokens'].apply(' '.join)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAQ1ZgqnCjsp",
        "outputId": "95b0f9dc-e296-4b7d-b8c3-563a22ff22f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ejemplo de tokens: \n",
            "0    [one, review, mention, watch, oz, episod, 'll,...\n",
            "1    [wonder, littl, product, film, techniqu, unass...\n",
            "2    [thought, wonder, way, spend, time, hot, summe...\n",
            "Name: tokens, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(f\"Ejemplo de tokens: \\n{df['tokens'].iloc[0:3][:6]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Dividir el conjunto en train/test (ej. 70/30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño del conjunto: \n",
            "      X_train: 35000\n",
            "      X_test: 15000\n",
            "      y_train: 35000\n",
            "      y_test: 15000\n",
            "      \n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['clean_text']\n",
        "y = df['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"\"\"Tamaño del conjunto: \n",
        "      X_train: {len(X_train)}\n",
        "      X_test: {len(X_test)}\n",
        "      y_train: {len(y_train)}\n",
        "      y_test: {len(y_test)}\n",
        "      \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Representaciones\n",
        "\n",
        "1.\tBolsa de Palabras (BoW)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   X_train_bow shape: (35000, 7000)\n",
            "   X_test_bow shape: (15000, 7000)\n",
            "   Vocabulario: 7000 palabras\n",
            "\n",
            "Primeras 10 palabras del vocabulario:\n",
            "['aaron' 'abandon' 'abbott' 'abc' 'abduct' 'abil' 'abl' 'aboard' 'abomin'\n",
            " 'aborigin']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow_vectorizer = CountVectorizer(\n",
        "    max_features=7000,      \n",
        "    min_df=5,               \n",
        "    max_df=0.8,\n",
        "    ngram_range=(1, 1)     \n",
        ")\n",
        "\n",
        "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
        "X_test_bow = bow_vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"   X_train_bow shape: {X_train_bow.shape}\")\n",
        "print(f\"   X_test_bow shape: {X_test_bow.shape}\")\n",
        "print(f\"   Vocabulario: {len(bow_vectorizer.get_feature_names_out())} palabras\")\n",
        "\n",
        "print(\"\\nPrimeras 10 palabras del vocabulario:\")\n",
        "print(bow_vectorizer.get_feature_names_out()[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.\tn-gramas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (35000, 7000)\n",
            "Total n-gramas: 7000\n",
            "\n",
            "Ejemplos de n-gramas para tipo de sentimiento:\n",
            "['absolut', 'absolut love', 'absolut noth', 'absorb', 'also', 'also enjoy', 'also featur', 'also get', 'also good', 'also great']\n"
          ]
        }
      ],
      "source": [
        "ngram_vectorizer = CountVectorizer(\n",
        "    max_features=7000,      \n",
        "    min_df=5,               \n",
        "    max_df=0.8,\n",
        "    ngram_range=(1, 3)     \n",
        ")\n",
        "\n",
        "X_train_ngrams = ngram_vectorizer.fit_transform(X_train)\n",
        "X_test_ngrams = ngram_vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "print(f\"Train shape: {X_train_ngrams.shape}\")\n",
        "print(f\"Total n-gramas: {len(ngram_vectorizer.get_feature_names_out())}\")\n",
        "print(\"\\nEjemplos de n-gramas para tipo de sentimiento:\")\n",
        "\n",
        "\n",
        "ngrams_ejemplos = []\n",
        "for ngram in ngram_vectorizer.get_feature_names_out():\n",
        "    if any(phrase in ngram for phrase in ['not', 'very', 'really', 'too', 'so', 'never']):\n",
        "        ngrams_ejemplos.append(ngram)\n",
        "    if len(ngrams_ejemplos) >= 10:\n",
        "        break\n",
        "\n",
        "print(ngrams_ejemplos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (35000, 1000)\n",
            "Test shape: (15000, 1000)\n",
            "\n",
            "Ejemplo de pesos:\n",
            "  steal: 0.3536\n",
            "  train: 0.3454\n",
            "  drive: 0.3335\n",
            "  hit: 0.2947\n",
            "  guy: 0.2270\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=1000,\n",
        "    ngram_range=(1, 2)\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "print(f\"Train shape: {X_train_tfidf.shape}\")\n",
        "print(f\"Test shape: {X_test_tfidf.shape}\")\n",
        "\n",
        "\n",
        "print(\"\\nEjemplo de pesos:\")\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "primer_review = X_train_tfidf[0].toarray()[0]\n",
        "top_indices = primer_review.argsort()[-5:][::-1]  # primeras 5 palabras con mayor peso\n",
        "\n",
        "for idx in top_indices:\n",
        "    if primer_review[idx] > 0:\n",
        "        print(f\"  {feature_names[idx]}: {primer_review[idx]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Word2Vec Google News (preentrenado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.downloader as api\n",
        "\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "wv = api.load('word2vec-google-news-300')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (35000, 300)\n",
            "Test shape: (15000, 300)\n",
            "Dimensionalidad de embeddings: 300\n",
            "\n",
            "Similitud 'good' - 'excellent': 0.644\n"
          ]
        }
      ],
      "source": [
        "# Promedio de un texto\n",
        "def get_text_embedding(text, model):\n",
        "    words = text.split()\n",
        "    vectors = []\n",
        "    for word in words:\n",
        "        if word in model:\n",
        "            vectors.append(model[word])\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "\n",
        "X_train_w2v = np.array([get_text_embedding(text, wv) for text in X_train])\n",
        "X_test_w2v = np.array([get_text_embedding(text, wv) for text in X_test])\n",
        "\n",
        "print(f\"Train shape: {X_train_w2v.shape}\")\n",
        "print(f\"Test shape: {X_test_w2v.shape}\")\n",
        "print(f\"Dimensionalidad de embeddings: {wv.vector_size}\")\n",
        "\n",
        "# Ejemplo de similitud\n",
        "if 'good' in wv and 'excellent' in wv:\n",
        "    similitud = wv.similarity('good', 'excellent')\n",
        "    print(f\"\\nSimilitud 'good' - 'excellent': {similitud:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Word2Vec propio (entrenado con el corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (35000, 100)\n",
            "Test shape: (15000, 100)\n",
            "Vocabulario: 27088 palabras\n",
            "\n",
            "Palabras similares a 'good': [('decent', 0.7612664103507996), ('great', 0.7122461199760437), ('bad', 0.7096006870269775)]\n"
          ]
        }
      ],
      "source": [
        "w2v_propio = Word2Vec(\n",
        "    sentences=df['tokens'],  \n",
        "    vector_size=100,         \n",
        "    window=5,                # Ventana de contexto\n",
        "    min_count=5,             \n",
        "    workers=4\n",
        ")\n",
        "\n",
        "# obtención de embeddings (promedio) \n",
        "def get_embedding(tokens, model):\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        if token in model.wv:\n",
        "            vectors.append(model.wv[token])\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "\n",
        "X_train_w2v_propio = np.array([get_embedding(tokens, w2v_propio) for tokens in df['tokens'].iloc[X_train.index]])\n",
        "X_test_w2v_propio = np.array([get_embedding(tokens, w2v_propio) for tokens in df['tokens'].iloc[X_test.index]])\n",
        "\n",
        "\n",
        "print(f\"Train shape: {X_train_w2v_propio.shape}\")\n",
        "print(f\"Test shape: {X_test_w2v_propio.shape}\")\n",
        "print(f\"Vocabulario: {len(w2v_propio.wv.key_to_index)} palabras\")\n",
        "\n",
        "# Ejemplo de palabras similares\n",
        "if 'good' in w2v_propio.wv:\n",
        "    similares = w2v_propio.wv.most_similar('good', topn=3)\n",
        "    print(f\"\\nPalabras similares a 'good': {similares}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Modelos de Clasificación.\n",
        "\n",
        "Se realizó la elección de 3 modelos de clasificación: Bósques de decisión, SVC y Regresión logistica\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "BOW:\n",
            "\n",
            "Random Forest: Entrenado\n",
            "KNN: Entrenado\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bugy1\\anaconda3\\envs\\pln\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "\n",
            "Increase the number of iterations to improve the convergence (max_iter=100).\n",
            "You might also want to scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression: Entrenado\n",
            "\n",
            "N-gramas:\n",
            "\n",
            "Random Forest: Entrenado\n",
            "KNN: Entrenado\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bugy1\\anaconda3\\envs\\pln\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "\n",
            "Increase the number of iterations to improve the convergence (max_iter=100).\n",
            "You might also want to scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression: Entrenado\n",
            "\n",
            "TF-IDF:\n",
            "\n",
            "Random Forest: Entrenado\n",
            "KNN: Entrenado\n",
            "Logistic Regression: Entrenado\n",
            "\n",
            "Word2Vec Propio:\n",
            "\n",
            "Random Forest: Entrenado\n",
            "KNN: Entrenado\n",
            "Logistic Regression: Entrenado\n",
            "\n",
            "Word2Vec Google:\n",
            "\n",
            "Random Forest: Entrenado\n",
            "KNN: Entrenado\n",
            "Logistic Regression: Entrenado\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "representaciones = {\n",
        "    'BOW': (X_train_bow,X_test_bow),\n",
        "    'N-gramas': (X_train_ngrams,X_test_ngrams), \n",
        "    'TF-IDF': (X_train_tfidf,X_test_tfidf),\n",
        "    'Word2Vec Propio': (X_train_w2v_propio, X_test_w2v_propio),\n",
        "    'Word2Vec Google': (X_train_w2v,X_test_w2v)  \n",
        "}\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "for rep_name, (X_train_rep, X_test_rep) in representaciones.items():\n",
        "    resultados[rep_name] = {}\n",
        "    \n",
        "    models_rep = {\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'KNN': KNeighborsClassifier(),\n",
        "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=100)\n",
        "    }\n",
        "    print(f\"\\n{rep_name}:\\n\")\n",
        "    for model_name, model in models_rep.items():\n",
        "        # Entrenamiento y predicción\n",
        "        model.fit(X_train_rep, y_train)\n",
        "        y_train_pred = model.predict(X_train_rep)\n",
        "        y_test_pred = model.predict(X_test_rep)\n",
        "        print(f\"{model_name}: Entrenado\")\n",
        "        \n",
        "        # Métricas\n",
        "        train_acc = accuracy_score(y_train, y_train_pred)\n",
        "        test_acc = accuracy_score(y_test, y_test_pred)\n",
        "        report = classification_report(y_test, y_test_pred, output_dict=True, digits=4)\n",
        "        \n",
        "        # Guardar resultados\n",
        "        resultados[rep_name][model_name] = {\n",
        "            'train_accuracy': train_acc,\n",
        "            'test_accuracy': test_acc,\n",
        "            'classification_report': report,\n",
        "            'model': model  \n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluación "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- BOW ---\n",
            "\n",
            "Random Forest:\n",
            "  Accuracy Train: 1.0000\n",
            "  Accuracy Test:  0.8497\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.8468  0.8494   0.8481\n",
            "    positive    0.8525  0.8499   0.8512\n",
            "\n",
            "KNN:\n",
            "  Accuracy Train: 0.7595\n",
            "  Accuracy Test:  0.6514\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.6464  0.6501   0.6482\n",
            "    positive    0.6564  0.6527   0.6545\n",
            "\n",
            "Logistic Regression:\n",
            "  Accuracy Train: 0.9589\n",
            "  Accuracy Test:  0.8701\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.8728  0.8629   0.8678\n",
            "    positive    0.8676  0.8772   0.8724\n",
            "\n",
            "--- N-gramas ---\n",
            "\n",
            "Random Forest:\n",
            "  Accuracy Train: 1.0000\n",
            "  Accuracy Test:  0.8496\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.8460  0.8504   0.8482\n",
            "    positive    0.8531  0.8489   0.8510\n",
            "\n",
            "KNN:\n",
            "  Accuracy Train: 0.7390\n",
            "  Accuracy Test:  0.6257\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.6142  0.6517   0.6324\n",
            "    positive    0.6383  0.6002   0.6187\n",
            "\n",
            "Logistic Regression:\n",
            "  Accuracy Train: 0.9624\n",
            "  Accuracy Test:  0.8721\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.8708  0.8703   0.8706\n",
            "    positive    0.8734  0.8739   0.8737\n",
            "\n",
            "--- TF-IDF ---\n",
            "\n",
            "Random Forest:\n",
            "  Accuracy Train: 1.0000\n",
            "  Accuracy Test:  0.8344\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.8283  0.8386   0.8334\n",
            "    positive    0.8405  0.8303   0.8353\n",
            "\n",
            "KNN:\n",
            "  Accuracy Train: 0.8297\n",
            "  Accuracy Test:  0.7372\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.7598  0.6845   0.7202\n",
            "    positive    0.7191  0.7886   0.7523\n",
            "\n",
            "Logistic Regression:\n",
            "  Accuracy Train: 0.8769\n",
            "  Accuracy Test:  0.8664\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.8704  0.8572   0.8638\n",
            "    positive    0.8626  0.8753   0.8689\n",
            "\n",
            "--- Word2Vec Propio ---\n",
            "\n",
            "Random Forest:\n",
            "  Accuracy Train: 1.0000\n",
            "  Accuracy Test:  0.8364\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.8429  0.8222   0.8324\n",
            "    positive    0.8304  0.8503   0.8402\n",
            "\n",
            "KNN:\n",
            "  Accuracy Train: 0.8685\n",
            "  Accuracy Test:  0.8039\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.7908  0.8199   0.8051\n",
            "    positive    0.8175  0.7882   0.8026\n",
            "\n",
            "Logistic Regression:\n",
            "  Accuracy Train: 0.8660\n",
            "  Accuracy Test:  0.8618\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.8638  0.8551   0.8594\n",
            "    positive    0.8599  0.8684   0.8641\n",
            "\n",
            "--- Word2Vec Google ---\n",
            "\n",
            "Random Forest:\n",
            "  Accuracy Train: 1.0000\n",
            "  Accuracy Test:  0.7717\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.7677  0.7714   0.7696\n",
            "    positive    0.7757  0.7720   0.7739\n",
            "\n",
            "KNN:\n",
            "  Accuracy Train: 0.8281\n",
            "  Accuracy Test:  0.7315\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.7257  0.7339   0.7298\n",
            "    positive    0.7372  0.7291   0.7331\n",
            "\n",
            "Logistic Regression:\n",
            "  Accuracy Train: 0.8226\n",
            "  Accuracy Test:  0.8141\n",
            "\n",
            "  Métricas por clase:\n",
            "    Clase      Precision  Recall  F1-Score\n",
            "    -------------------------------------\n",
            "    negative    0.8111  0.8131   0.8121\n",
            "    positive    0.8171  0.8151   0.8161\n"
          ]
        }
      ],
      "source": [
        "for rep_name, models_dict in resultados.items():\n",
        "    print(f\"\\n--- {rep_name} ---\")\n",
        "    \n",
        "    for model_name, metrics in models_dict.items():\n",
        "        report = metrics['classification_report']\n",
        "        \n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(f\"  Accuracy Train: {metrics['train_accuracy']:.4f}\")\n",
        "        print(f\"  Accuracy Test:  {metrics['test_accuracy']:.4f}\")\n",
        "        \n",
        "        print(f\"\\n  Métricas por clase:\")\n",
        "        print(f\"    Clase      Precision  Recall  F1-Score\")\n",
        "        print(f\"    -------------------------------------\")\n",
        "        \n",
        "        for class_name in ['negative', 'positive']:\n",
        "            if class_name in report:\n",
        "                print(f\"    {class_name:9} {report[class_name]['precision']:8.4f} {report[class_name]['recall']:7.4f} {report[class_name]['f1-score']:8.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resultados\n",
        "\n",
        "## BOW (Bag of Words)\n",
        "\n",
        "### Random Forest\n",
        "- **Accuracy Train**: 1.0000\n",
        "- **Accuracy Test**: 0.8497\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.8468    | 0.8494 | 0.8481   |\n",
        "| positive  | 0.8525    | 0.8499 | 0.8512   |\n",
        "\n",
        "### KNN\n",
        "- **Accuracy Train**: 0.7595\n",
        "- **Accuracy Test**: 0.6514\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.6464    | 0.6501 | 0.6482   |\n",
        "| positive  | 0.6564    | 0.6527 | 0.6545   |\n",
        "\n",
        "### Logistic Regression\n",
        "- **Accuracy Train**: 0.9589\n",
        "- **Accuracy Test**: 0.8701\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.8728    | 0.8629 | 0.8678   |\n",
        "| positive  | 0.8676    | 0.8772 | 0.8724   |\n",
        "\n",
        "## N-gramas\n",
        "\n",
        "### Random Forest\n",
        "- **Accuracy Train**: 1.0000\n",
        "- **Accuracy Test**: 0.8496\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.8460    | 0.8504 | 0.8482   |\n",
        "| positive  | 0.8531    | 0.8489 | 0.8510   |\n",
        "\n",
        "### KNN\n",
        "- **Accuracy Train**: 0.7390\n",
        "- **Accuracy Test**: 0.6257\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.6142    | 0.6517 | 0.6324   |\n",
        "| positive  | 0.6383    | 0.6002 | 0.6187   |\n",
        "\n",
        "### Logistic Regression\n",
        "- **Accuracy Train**: 0.9624\n",
        "- **Accuracy Test**: 0.8721\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.8708    | 0.8703 | 0.8706   |\n",
        "| positive  | 0.8734    | 0.8739 | 0.8737   |\n",
        "\n",
        "## TF-IDF\n",
        "\n",
        "### Random Forest\n",
        "- **Accuracy Train**: 1.0000\n",
        "- **Accuracy Test**: 0.8344\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.8283    | 0.8386 | 0.8334   |\n",
        "| positive  | 0.8405    | 0.8303 | 0.8353   |\n",
        "\n",
        "### KNN\n",
        "- **Accuracy Train**: 0.8297\n",
        "- **Accuracy Test**: 0.7372\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.7598    | 0.6845 | 0.7202   |\n",
        "| positive  | 0.7191    | 0.7886 | 0.7523   |\n",
        "\n",
        "### Logistic Regression\n",
        "- **Accuracy Train**: 0.8769\n",
        "- **Accuracy Test**: 0.8664\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.8704    | 0.8572 | 0.8638   |\n",
        "| positive  | 0.8626    | 0.8753 | 0.8689   |\n",
        "\n",
        "## Word2Vec Propio\n",
        "\n",
        "### Random Forest\n",
        "- **Accuracy Train**: 1.0000\n",
        "- **Accuracy Test**: 0.8364\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.8429    | 0.8222 | 0.8324   |\n",
        "| positive  | 0.8304    | 0.8503 | 0.8402   |\n",
        "\n",
        "### KNN\n",
        "- **Accuracy Train**: 0.8685\n",
        "- **Accuracy Test**: 0.8039\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.7908    | 0.8199 | 0.8051   |\n",
        "| positive  | 0.8175    | 0.7882 | 0.8026   |\n",
        "\n",
        "### Logistic Regression\n",
        "- **Accuracy Train**: 0.8660\n",
        "- **Accuracy Test**: 0.8618\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.8638    | 0.8551 | 0.8594   |\n",
        "| positive  | 0.8599    | 0.8684 | 0.8641   |\n",
        "\n",
        "## Word2Vec Google\n",
        "\n",
        "### Random Forest\n",
        "- **Accuracy Train**: 1.0000\n",
        "- **Accuracy Test**: 0.7717\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.7677    | 0.7714 | 0.7696   |\n",
        "| positive  | 0.7757    | 0.7720 | 0.7739   |\n",
        "\n",
        "### KNN\n",
        "- **Accuracy Train**: 0.8281\n",
        "- **Accuracy Test**: 0.7315\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.7257    | 0.7339 | 0.7298   |\n",
        "| positive  | 0.7372    | 0.7291 | 0.7331   |\n",
        "\n",
        "### Logistic Regression\n",
        "- **Accuracy Train**: 0.8226\n",
        "- **Accuracy Test**: 0.8141\n",
        "\n",
        "| Clase     | Precision | Recall | F1-Score |\n",
        "|-----------|-----------|--------|----------|\n",
        "| negative  | 0.8111    | 0.8131 | 0.8121   |\n",
        "| positive  | 0.8171    | 0.8151 | 0.8161   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se observa que la representación más eficaz fue la de N-gramas combinada con regresión logística, alcanzando una precisión de 0.8721 en el conjunto de prueba. En segundo lugar, se posicionó el modelo basado en Bag of Words (BoW) con el mismo algoritmo, aunque con un rendimiento ligeramente inferior.\n",
        "\n",
        "Asimismo, al comparar el modelo Word2Vec entrenado localmente con el preentrenado de Google, se muestran diferencias significativas. El modelo propio mostró un desempeño superior, obteniendo una precisión de aproximadamente 0.8618 con regresión logística, contra 0.8141 alcanzado por el modelo de Google bajo las mismas condiciones.\n",
        "\n",
        "Cabe destacar que la regresión logística fue el algoritmo con mejor rendimiento en la mayoría de las representaciones evaluadas. El modelo basado en árboles de decisión no fue considerado en el análisis final debido a indicios claros de sobreajuste. Finalmente, se observa que el grado de generalización varía según el algoritmo utilizado, siendo la regresión logística la que presenta una menor diferencia entre los conjuntos de entrenamiento y prueba, lo que parece mostrar una mayor capacidad de correcta predicción.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusión\n",
        "\n",
        "En este proyecto se realizó la comparativa de diversas representaciones y el entrenamiento de cada una de ellas. Como se pudo observar, la representación en N-gramas demostró ser la más efectiva para el objetivo el cual era clasificar sentimientos positivos y negativos. El algoritmo donde alcanzó un mayor accuracy fue con regresión logística (cerca del 87%). Estos resultados se deben principalmente a la captura del contexto de los n-gramas. Los bigramas o trigramas permiten al modelo entender dichas reglas linguisticas los cuales son fundamentales para determinar el sentimiento de una manera precisa. \n",
        "\n",
        "Con respecto a los embeddings preentrenados y con el corpus propio, si existen diferencias significativas. El modelo propio alcanzó un accuracy aproximado de 86% mientras que el preentrenado obtuvo un aproximado de 81%. La razón es debido a que, el Word2Vec propio se especializó en este dominio específico. El modelo de Google es muy general y contiene embeddings relacionados a un lenguaje periodístico y de noticias, por lo cual no se alinea completamente a este contexto. \n",
        "\n",
        "Entre las limitaciones observadas con respecto a BOW, n-gramas y TF-IDF, en el caso de BOW, se sufre una pérdida completa con respecto al orden y el contexto de las palabras. En general esta representación trata cada palabra como independiente, además de generar matrices muy dispersas y una alta dimensionalidad con los embeddings. En el caso de los n-gramas, estos pueden experimentar combinaciones de palabras muy revueltas, además de que el número de características crece de manera exponencial con el tamaño de n, haciendo que algoritmos como random forest experimenten un overffiting.  Finalmente TF-IDF mostró una pérdida en el rendimiento en comparación con BOW simple. Probablemente para estas clasificaciones la frecuencia de las palabras sea importante, quiere decir que puede que este algoritmo esté eliminando señales importantes para la tarea. \n",
        "\n",
        "En un proyecto real se podría hacer uso de una combinación de algunas de estas representaciones. Por ejemplo, la representación de n-gramas con regresión logística podría ser la principal. Posterior a eso, la generación de embeddings se podrían entrenar con el corpus propio (Word2Vec propio) y realizar el entrenamiento con el modelo anteriormente dicho. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pln",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
