{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: NLTK Text\n",
    "## Bogdan Kaleb García Rivera MIA-2\n",
    "\n",
    "\n",
    "__Objetivo__\n",
    "\n",
    "- Practicar el uso del objeto Text de la librería NLTK\n",
    "\n",
    "__Desarrollo__\n",
    "\n",
    "Utilizar el conjunto de datos que resultante del [ejercicio](../../L001-Intro-TA4RE/L001-6-regex/code/L001-6-1e-regex.ipynb) (este conjunto de datos debería de contener todas las evaluaciones registradas en el dataset `'amazon_fine_food_reviews-clean.csv'` limpias y listas para realizar un análisis).\n",
    "\n",
    "Realizar lo siguiente:\n",
    "\n",
    "1. Aplica el método 'word_tokenize' de nltk para separar todas las evaluaciones por palabras.\n",
    "2. Genera una sola lista con todas las listas que obtenida en el paso 1, para crear un objeto `nltk.Text`.\n",
    "3. Buscar las concordancias de las palabras 'boy' y 'girl'.\n",
    "4. Buscar las palabras que tengan contextos similares a las palabras 'boy' y 'girl'.\n",
    "5. Buscar los contextos que tengan en común las palabras 'boy' y 'girl'.\n",
    "6. Cuantificar la riqueza léxica de tu conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente se puede visualizar el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>profile_name</th>\n",
       "      <th>helpfulness_numerator</th>\n",
       "      <th>helpfulness_denominator</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258510</td>\n",
       "      <td>b00168v34w</td>\n",
       "      <td>a1672lh9s1xo70</td>\n",
       "      <td>lorna j loomis canadian dog fancier</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1266796800</td>\n",
       "      <td>misleading refer pods</td>\n",
       "      <td>this coffee does not come individual pods k cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207915</td>\n",
       "      <td>b000cqid2y</td>\n",
       "      <td>a42cjc66xo0h7</td>\n",
       "      <td>scott schimmel a butterfly dreaming</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1279497600</td>\n",
       "      <td>delicious</td>\n",
       "      <td>i little skeptical after looking list ingredie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>522649</td>\n",
       "      <td>b007tjgz0y</td>\n",
       "      <td>a16qzbg2un6z3x</td>\n",
       "      <td>toology toology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1335830400</td>\n",
       "      <td>one my favs</td>\n",
       "      <td>gloia jeans butter toffee one my favorite kcup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>393368</td>\n",
       "      <td>b000w7puow</td>\n",
       "      <td>a3j21cqzg60k35</td>\n",
       "      <td>hsieh pei hsuan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1265673600</td>\n",
       "      <td>tasty</td>\n",
       "      <td>my families friends love planters peanuts i bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178178</td>\n",
       "      <td>b002fx2ioq</td>\n",
       "      <td>a1z7xv6ju0ev8m</td>\n",
       "      <td>barbara barbara</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1301788800</td>\n",
       "      <td>organic valley white 1 milkfat lowfat milk 8ou...</td>\n",
       "      <td>organic valley white milkfat lowfat milk ounce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  product_id         user_id                         profile_name  \\\n",
       "0  258510  b00168v34w  a1672lh9s1xo70  lorna j loomis canadian dog fancier   \n",
       "1  207915  b000cqid2y   a42cjc66xo0h7  scott schimmel a butterfly dreaming   \n",
       "2  522649  b007tjgz0y  a16qzbg2un6z3x                      toology toology   \n",
       "3  393368  b000w7puow  a3j21cqzg60k35                      hsieh pei hsuan   \n",
       "4  178178  b002fx2ioq  a1z7xv6ju0ev8m                      barbara barbara   \n",
       "\n",
       "   helpfulness_numerator  helpfulness_denominator  score        time  \\\n",
       "0                     13                       14      3  1266796800   \n",
       "1                      2                        2      5  1279497600   \n",
       "2                      0                        0      5  1335830400   \n",
       "3                      2                        2      5  1265673600   \n",
       "4                      1                        6      1  1301788800   \n",
       "\n",
       "                                             summary  \\\n",
       "0                              misleading refer pods   \n",
       "1                                          delicious   \n",
       "2                                        one my favs   \n",
       "3                                              tasty   \n",
       "4  organic valley white 1 milkfat lowfat milk 8ou...   \n",
       "\n",
       "                                                text  \n",
       "0  this coffee does not come individual pods k cu...  \n",
       "1  i little skeptical after looking list ingredie...  \n",
       "2  gloia jeans butter toffee one my favorite kcup...  \n",
       "3  my families friends love planters peanuts i bo...  \n",
       "4  organic valley white milkfat lowfat milk ounce...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('./data/amazon_fine_food_reviews-clean-regex.csv')\n",
    "df.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el uso de la librería de NLTK se tuvieron ciertos problemas con la instalación, por lo que el siguiente código solventa la solución del error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/bogdanrivera/Escritorio/pr2-1-ejercicios-\n",
      "[nltk_data]     notebooks-BogdanRivera/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "\n",
    "ruta_descarga = os.path.join(os.getcwd(), 'nltk_data') # Descargar en el directorio actual\n",
    "nltk.download('punkt_tab', download_dir=ruta_descarga)\n",
    "\n",
    "# Agregar la ruta de descarga a las rutas de búsqueda de NLTK\n",
    "nltk.data.path.append(ruta_descarga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Aplica el método 'word_tokenize' de nltk para separar todas las evaluaciones por palabras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>profile_name</th>\n",
       "      <th>helpfulness_numerator</th>\n",
       "      <th>helpfulness_denominator</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258510</td>\n",
       "      <td>b00168v34w</td>\n",
       "      <td>a1672lh9s1xo70</td>\n",
       "      <td>lorna j loomis canadian dog fancier</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1266796800</td>\n",
       "      <td>misleading refer pods</td>\n",
       "      <td>this coffee does not come individual pods k cu...</td>\n",
       "      <td>[this, coffee, does, not, come, individual, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207915</td>\n",
       "      <td>b000cqid2y</td>\n",
       "      <td>a42cjc66xo0h7</td>\n",
       "      <td>scott schimmel a butterfly dreaming</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1279497600</td>\n",
       "      <td>delicious</td>\n",
       "      <td>i little skeptical after looking list ingredie...</td>\n",
       "      <td>[i, little, skeptical, after, looking, list, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>522649</td>\n",
       "      <td>b007tjgz0y</td>\n",
       "      <td>a16qzbg2un6z3x</td>\n",
       "      <td>toology toology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1335830400</td>\n",
       "      <td>one my favs</td>\n",
       "      <td>gloia jeans butter toffee one my favorite kcup...</td>\n",
       "      <td>[gloia, jeans, butter, toffee, one, my, favori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>393368</td>\n",
       "      <td>b000w7puow</td>\n",
       "      <td>a3j21cqzg60k35</td>\n",
       "      <td>hsieh pei hsuan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1265673600</td>\n",
       "      <td>tasty</td>\n",
       "      <td>my families friends love planters peanuts i bo...</td>\n",
       "      <td>[my, families, friends, love, planters, peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178178</td>\n",
       "      <td>b002fx2ioq</td>\n",
       "      <td>a1z7xv6ju0ev8m</td>\n",
       "      <td>barbara barbara</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1301788800</td>\n",
       "      <td>organic valley white 1 milkfat lowfat milk 8ou...</td>\n",
       "      <td>organic valley white milkfat lowfat milk ounce...</td>\n",
       "      <td>[organic, valley, white, milkfat, lowfat, milk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  product_id         user_id                         profile_name  \\\n",
       "0  258510  b00168v34w  a1672lh9s1xo70  lorna j loomis canadian dog fancier   \n",
       "1  207915  b000cqid2y   a42cjc66xo0h7  scott schimmel a butterfly dreaming   \n",
       "2  522649  b007tjgz0y  a16qzbg2un6z3x                      toology toology   \n",
       "3  393368  b000w7puow  a3j21cqzg60k35                      hsieh pei hsuan   \n",
       "4  178178  b002fx2ioq  a1z7xv6ju0ev8m                      barbara barbara   \n",
       "\n",
       "   helpfulness_numerator  helpfulness_denominator  score        time  \\\n",
       "0                     13                       14      3  1266796800   \n",
       "1                      2                        2      5  1279497600   \n",
       "2                      0                        0      5  1335830400   \n",
       "3                      2                        2      5  1265673600   \n",
       "4                      1                        6      1  1301788800   \n",
       "\n",
       "                                             summary  \\\n",
       "0                              misleading refer pods   \n",
       "1                                          delicious   \n",
       "2                                        one my favs   \n",
       "3                                              tasty   \n",
       "4  organic valley white 1 milkfat lowfat milk 8ou...   \n",
       "\n",
       "                                                text  \\\n",
       "0  this coffee does not come individual pods k cu...   \n",
       "1  i little skeptical after looking list ingredie...   \n",
       "2  gloia jeans butter toffee one my favorite kcup...   \n",
       "3  my families friends love planters peanuts i bo...   \n",
       "4  organic valley white milkfat lowfat milk ounce...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [this, coffee, does, not, come, individual, po...  \n",
       "1  [i, little, skeptical, after, looking, list, i...  \n",
       "2  [gloia, jeans, butter, toffee, one, my, favori...  \n",
       "3  [my, families, friends, love, planters, peanut...  \n",
       "4  [organic, valley, white, milkfat, lowfat, milk...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['text'].apply(word_tokenize) # Aplica a la columna text y crea una nueva columna\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Genera una sola lista con todas las listas que obtenida en el paso 1, para crear un objeto `nltk.Text`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.text import Text\n",
    "all_words = [x for sublista in df['tokens'] for x in sublista] #Agrupa las palabras individuales\n",
    "\n",
    "# Crear un objeto nltk.Text\n",
    "nltk_text = Text(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Buscar las concordancias de las palabras 'boy' y 'girl'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordancias para boy:\n",
      "Displaying 25 of 75 matches:\n",
      " as recommended followed making one down letter boy oh boy not only my husband thrilled i now love \n",
      "ommended followed making one down letter boy oh boy not only my husband thrilled i now love vanilla\n",
      "ke cookies fudgey center yes theyre chewy gooey boy they sweet a bit too sweet my taste my husband \n",
      "side box as result i had throw it out my little boy month i got puff him he likes it very much i le\n",
      "me tin try got her back track so i ordered more boy did she love it it even smells good almost like\n",
      "ntent update after so far i so love mix my baby boy wont have eat yucky hard socalled bread again m\n",
      "t exactly which bin pet waste biobag can tossed boy i glad i called city before purchasing these ba\n",
      "t your reviews i would never have made purchase boy i glad take advice prior like many others out i\n",
      "admit i skeptical i thought i would give it try boy i amazed refreshing flavor more importantly how\n",
      "ry im glad have ordered bonsai tree from bonsai boy it arrived within week the tree well secured pe\n",
      " looking forward from ordering more from bonsai boy you probably already know whether not you like \n",
      "mall you can buy these half price jellybellycom boy did i feel ripped off when i discovered the tas\n",
      "hought sure product had as good as their others boy i right i made mix into cupcakes unlike other c\n",
      " my longtime vet after my year old russian blue boy developed chrystals hir urine hospitalized she \n",
      "ter my kitties i love catfood had some problems boy kitty after neutering he went off his food over\n",
      "okay so i bought tea based reviews amazonand oh boy it trully works my face had many ugly acne most\n",
      "animal crackers dont they well our threeyearold boy certainly does so my wife picked up ounce bag b\n",
      "acks hmmmmm i suspect these just as much her as boy well what can you do we already have them bag o\n",
      "t only lightly sweet nice snack treat of course boy loves them im going have problems staying away \n",
      "dnt put all crap it i might singe my nose hairs boy it strong you people who drink it without dilut\n",
      "le soup as i have done past store bought brands boy did i regret it haha if you dont have heat tole\n",
      "p bag loacker quadratini lemon wafer cookies oh boy these good they disappear real fast be ready ap\n",
      "icks up coopersmith telling his teammates every boy academy gets shot playing school within seconds\n",
      "id administers whipping jameson can barely look boy without cringing coopersmiths dark discoveries \n",
      " horrific wet runny stinky beyond belief my big boy who did mind his manners ate graduated amount m\n"
     ]
    }
   ],
   "source": [
    "print(\"Concordancias para boy:\")\n",
    "nltk_text.concordance(\"boy\", width=100)  # width ajusta el ancho del contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordancias para boy:\n",
      "Displaying 25 of 71 matches:\n",
      "ave all his teeth all his life plus both he his girl friend love taste i recently purchased keurig c\n",
      "ybody from all other trailers coming over i had girl three boobs from freak show sitting my lap then\n",
      "ear greenie bagmy tiny little italian greyhound girl gets greenie bedtime sometimes she starts pushi\n",
      "common big name cookiesnothing else compares my girl has loved these two years when local retail out\n",
      "we found manufacturer this one few treats wilhi girl enjoys just opened package discovered one twelv\n",
      "so quick easy normally i made from scratch kind girl wanted try these flavors i love them so high pr\n",
      "individually wrapped candies i bought as little girl from corner store cents piece these gold coins \n",
      "tmentthis food recommended my wife i our little girl poppy without reservation if you cant afford co\n",
      " more trips vet phew ive hearing product hungry girl i love peanut butter not all fat goes along it \n",
      " give her little something extra when shes good girl not have worry if she will get sick have allerg\n",
      "ultthey honestand reliable shopnice deal my chi girl loves these she gets excited when she hears wor\n",
      " from as some just recalled made chinamy little girl having trouble dry stools sorry i know gross fi\n",
      "huge problem dogs as they age i want my special girl stay healthy pain free happy as long as she can\n",
      " road i ordered these as suggestion from hungry girl website my husband i love them no nasty after t\n",
      "icious i havent had topping like since i little girl other brands have artifical too much sugar my t\n",
      "chy i just rescued male shih tzu he ate them my girl wasnt impressed i still searching usa made chew\n",
      "k mint dark chocolate reminds me chocolate mint girl scout cookies less sugarnd blue diamond dark ch\n",
      "seradish you will really enjoy mustard i island girl product where i feel i just got my straw into b\n",
      "om amazon these our onthego guarantee my little girl gets her fruits veggies she loves them now know\n",
      "ight my friend considers food lifesaver her old girl one big challenges lowcarb diet regime finding \n",
      "finetely does thank you helping me save my baby girl i like pepitas when i told seeds good me i star\n",
      "geing also needs some work my overweight little girl not only got down healthy size cured her lamene\n",
      "ry one dogs absolutely crazy taste food even my girl who we used have push finish her dinner now eat\n",
      "ng forward butter shortbread cookies i involved girl scouts years had my share shortbreads the size \n",
      "pact than regular cookiesthey taste almost like girl scout thin mint patty cookies they not however \n"
     ]
    }
   ],
   "source": [
    "print(\"Concordancias para boy:\")\n",
    "nltk_text.concordance(\"girl\", width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Buscar las palabras que tengan contextos similares a las palabras 'boy' y 'girl'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras con contextos similares para boy: \n",
      "\n",
      "so as when it dog again now then if while i flavor since you what one\n",
      "they me before yes well cat but coffee which tea all them bag brand\n",
      "product taste like great just however finally kids order salt whenever\n",
      "after buy amazon price out from and she still only best do him ones\n",
      "although husband boxes dogs things cats until stuff test sister items\n",
      "try did my favorite have store food item cook eat son we thing any\n",
      "juice too these chips greenies time once day everyday never deal\n",
      "walmart can though most bitter smell evening cereal drink snack more\n",
      "quality than unfortunately bad top point meat variety where eating\n",
      "sugar stars purchase hours sip reviews calories salty usually normal\n",
      "flakes starbucks hair bite yorkie puffs personally body heat doggies\n",
      "medicine okay pills smoothie success does not box packaging keurig\n",
      "expected little looking ingredients anyway glad delicious good\n"
     ]
    }
   ],
   "source": [
    "print('Palabras con contextos similares para boy: \\n')\n",
    "nltk_text.similar('boy',num=150) # Num permite el numero de palabras a mostrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras con contextos similares para girl: \n",
      "\n",
      "dog dogs one food cat favorite son friend wife office daughter coffee\n",
      "i off product taste me puppy if bit kids husband better body pricey\n",
      "sister it keurig tea did flavor friends when again water way house too\n",
      "spicy vet baby mouth disappointed bitter more experience things plant\n",
      "diet foods home cheaper tart sugar family mom knowledge mother bottles\n",
      "own hair crunchy lab thinking skin packets bland female household door\n",
      "guests grandson guy leery packaging what little im its has butter buy\n",
      "white pack high price bag local store brand as her they different flat\n",
      "bowl differently should whom since teeth pantry container while just\n",
      "deal sauce neighbor powder life well though parents smooth him he\n",
      "dinner cereal energy bars snack hesitant quality ones protein pickiest\n",
      "theyre days although order waste batch formula bigger dressing some\n",
      "plants machine salt cats dry change wow nephews flavors salmon cooking\n",
      "recipes vizsla sample\n"
     ]
    }
   ],
   "source": [
    "print('Palabras con contextos similares para girl: \\n')\n",
    "nltk_text.similar('girl',num=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Buscar los contextos que tengan en común las palabras 'boy' y 'girl'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "little_i\n"
     ]
    }
   ],
   "source": [
    "nltk_text.common_contexts(['boy','girl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Cuantificar la riqueza léxica de tu conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La riqueza léxica es de 4.26%\n"
     ]
    }
   ],
   "source": [
    "riqueza = len(set(nltk_text))/len(nltk_text)\n",
    "\n",
    "print(f\"La riqueza léxica es de {riqueza*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
